{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.99965866423939,
  "eval_steps": 1000,
  "global_step": 13182,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022755717373990215,
      "grad_norm": 1.7129552364349365,
      "learning_rate": 1e-05,
      "loss": 3.967,
      "step": 100
    },
    {
      "epoch": 0.04551143474798043,
      "grad_norm": 1.3928332328796387,
      "learning_rate": 2e-05,
      "loss": 3.1911,
      "step": 200
    },
    {
      "epoch": 0.06826715212197064,
      "grad_norm": 1.121227502822876,
      "learning_rate": 3e-05,
      "loss": 3.1284,
      "step": 300
    },
    {
      "epoch": 0.09102286949596086,
      "grad_norm": 0.9865557551383972,
      "learning_rate": 4e-05,
      "loss": 3.0939,
      "step": 400
    },
    {
      "epoch": 0.11377858686995107,
      "grad_norm": 0.9408854842185974,
      "learning_rate": 5e-05,
      "loss": 3.0461,
      "step": 500
    },
    {
      "epoch": 0.13653430424394128,
      "grad_norm": 0.8846441507339478,
      "learning_rate": 6e-05,
      "loss": 2.9815,
      "step": 600
    },
    {
      "epoch": 0.15929002161793152,
      "grad_norm": 0.9091459512710571,
      "learning_rate": 7e-05,
      "loss": 2.9294,
      "step": 700
    },
    {
      "epoch": 0.18204573899192172,
      "grad_norm": 0.8054203391075134,
      "learning_rate": 8e-05,
      "loss": 2.885,
      "step": 800
    },
    {
      "epoch": 0.20480145636591193,
      "grad_norm": 0.771289587020874,
      "learning_rate": 9e-05,
      "loss": 2.8555,
      "step": 900
    },
    {
      "epoch": 0.22755717373990214,
      "grad_norm": 0.7021647691726685,
      "learning_rate": 0.0001,
      "loss": 2.8253,
      "step": 1000
    },
    {
      "epoch": 0.22755717373990214,
      "eval_loss": 2.830706834793091,
      "eval_runtime": 14.0541,
      "eval_samples_per_second": 396.113,
      "eval_steps_per_second": 24.762,
      "step": 1000
    },
    {
      "epoch": 0.2503128911138924,
      "grad_norm": 0.6900992393493652,
      "learning_rate": 0.00011000000000000002,
      "loss": 2.8007,
      "step": 1100
    },
    {
      "epoch": 0.27306860848788256,
      "grad_norm": 0.670677900314331,
      "learning_rate": 0.00012,
      "loss": 2.7803,
      "step": 1200
    },
    {
      "epoch": 0.2958243258618728,
      "grad_norm": 0.6330938935279846,
      "learning_rate": 0.00013000000000000002,
      "loss": 2.7564,
      "step": 1300
    },
    {
      "epoch": 0.31858004323586303,
      "grad_norm": 0.6133373975753784,
      "learning_rate": 0.00014,
      "loss": 2.7433,
      "step": 1400
    },
    {
      "epoch": 0.3413357606098532,
      "grad_norm": 0.5601828098297119,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.7259,
      "step": 1500
    },
    {
      "epoch": 0.36409147798384345,
      "grad_norm": 0.541846752166748,
      "learning_rate": 0.00016,
      "loss": 2.7098,
      "step": 1600
    },
    {
      "epoch": 0.38684719535783363,
      "grad_norm": 0.5367089509963989,
      "learning_rate": 0.00017,
      "loss": 2.6935,
      "step": 1700
    },
    {
      "epoch": 0.40960291273182386,
      "grad_norm": 0.49171528220176697,
      "learning_rate": 0.00018,
      "loss": 2.6817,
      "step": 1800
    },
    {
      "epoch": 0.4323586301058141,
      "grad_norm": 0.501632571220398,
      "learning_rate": 0.00019,
      "loss": 2.668,
      "step": 1900
    },
    {
      "epoch": 0.4551143474798043,
      "grad_norm": 0.48123472929000854,
      "learning_rate": 0.0002,
      "loss": 2.6585,
      "step": 2000
    },
    {
      "epoch": 0.4551143474798043,
      "eval_loss": 2.6959331035614014,
      "eval_runtime": 14.0429,
      "eval_samples_per_second": 396.429,
      "eval_steps_per_second": 24.781,
      "step": 2000
    },
    {
      "epoch": 0.4778700648537945,
      "grad_norm": 0.48273640871047974,
      "learning_rate": 0.00019821141119656592,
      "loss": 2.6465,
      "step": 2100
    },
    {
      "epoch": 0.5006257822277848,
      "grad_norm": 0.46650031208992004,
      "learning_rate": 0.00019642282239313184,
      "loss": 2.6383,
      "step": 2200
    },
    {
      "epoch": 0.5233814996017749,
      "grad_norm": 0.4905090630054474,
      "learning_rate": 0.00019463423358969775,
      "loss": 2.6243,
      "step": 2300
    },
    {
      "epoch": 0.5461372169757651,
      "grad_norm": 0.43035510182380676,
      "learning_rate": 0.00019284564478626366,
      "loss": 2.6136,
      "step": 2400
    },
    {
      "epoch": 0.5688929343497554,
      "grad_norm": 0.4258307218551636,
      "learning_rate": 0.00019105705598282955,
      "loss": 2.6025,
      "step": 2500
    },
    {
      "epoch": 0.5916486517237456,
      "grad_norm": 0.44353780150413513,
      "learning_rate": 0.00018926846717939546,
      "loss": 2.5926,
      "step": 2600
    },
    {
      "epoch": 0.6144043690977358,
      "grad_norm": 0.43553560972213745,
      "learning_rate": 0.00018747987837596137,
      "loss": 2.5864,
      "step": 2700
    },
    {
      "epoch": 0.6371600864717261,
      "grad_norm": 0.43055200576782227,
      "learning_rate": 0.0001856912895725273,
      "loss": 2.5751,
      "step": 2800
    },
    {
      "epoch": 0.6599158038457162,
      "grad_norm": 0.41376012563705444,
      "learning_rate": 0.0001839027007690932,
      "loss": 2.5667,
      "step": 2900
    },
    {
      "epoch": 0.6826715212197064,
      "grad_norm": 0.4355972111225128,
      "learning_rate": 0.00018211411196565911,
      "loss": 2.5644,
      "step": 3000
    },
    {
      "epoch": 0.6826715212197064,
      "eval_loss": 2.6106090545654297,
      "eval_runtime": 14.0475,
      "eval_samples_per_second": 396.299,
      "eval_steps_per_second": 24.773,
      "step": 3000
    },
    {
      "epoch": 0.7054272385936967,
      "grad_norm": 0.4153537154197693,
      "learning_rate": 0.00018032552316222503,
      "loss": 2.5591,
      "step": 3100
    },
    {
      "epoch": 0.7281829559676869,
      "grad_norm": 0.41593682765960693,
      "learning_rate": 0.00017853693435879094,
      "loss": 2.5528,
      "step": 3200
    },
    {
      "epoch": 0.7509386733416771,
      "grad_norm": 0.4099932014942169,
      "learning_rate": 0.00017674834555535685,
      "loss": 2.545,
      "step": 3300
    },
    {
      "epoch": 0.7736943907156673,
      "grad_norm": 0.40862736105918884,
      "learning_rate": 0.00017495975675192274,
      "loss": 2.5367,
      "step": 3400
    },
    {
      "epoch": 0.7964501080896575,
      "grad_norm": 0.3744737505912781,
      "learning_rate": 0.00017317116794848865,
      "loss": 2.5312,
      "step": 3500
    },
    {
      "epoch": 0.8192058254636477,
      "grad_norm": 0.39550596475601196,
      "learning_rate": 0.00017138257914505457,
      "loss": 2.5287,
      "step": 3600
    },
    {
      "epoch": 0.8419615428376379,
      "grad_norm": 0.37263473868370056,
      "learning_rate": 0.00016959399034162048,
      "loss": 2.5269,
      "step": 3700
    },
    {
      "epoch": 0.8647172602116282,
      "grad_norm": 0.3979664742946625,
      "learning_rate": 0.0001678054015381864,
      "loss": 2.5166,
      "step": 3800
    },
    {
      "epoch": 0.8874729775856184,
      "grad_norm": 0.3869766592979431,
      "learning_rate": 0.0001660168127347523,
      "loss": 2.516,
      "step": 3900
    },
    {
      "epoch": 0.9102286949596086,
      "grad_norm": 0.37252286076545715,
      "learning_rate": 0.0001642282239313182,
      "loss": 2.5117,
      "step": 4000
    },
    {
      "epoch": 0.9102286949596086,
      "eval_loss": 2.5679194927215576,
      "eval_runtime": 14.0991,
      "eval_samples_per_second": 394.847,
      "eval_steps_per_second": 24.682,
      "step": 4000
    },
    {
      "epoch": 0.9329844123335989,
      "grad_norm": 0.36209121346473694,
      "learning_rate": 0.0001624396351278841,
      "loss": 2.5062,
      "step": 4100
    },
    {
      "epoch": 0.955740129707589,
      "grad_norm": 0.3946315050125122,
      "learning_rate": 0.00016065104632445002,
      "loss": 2.5015,
      "step": 4200
    },
    {
      "epoch": 0.9784958470815792,
      "grad_norm": 0.3705155849456787,
      "learning_rate": 0.00015886245752101593,
      "loss": 2.4982,
      "step": 4300
    },
    {
      "epoch": 1.0012515644555695,
      "grad_norm": 0.384217768907547,
      "learning_rate": 0.00015707386871758182,
      "loss": 2.4932,
      "step": 4400
    },
    {
      "epoch": 1.0240072818295596,
      "grad_norm": 0.37587642669677734,
      "learning_rate": 0.00015528527991414773,
      "loss": 2.4746,
      "step": 4500
    },
    {
      "epoch": 1.0467629992035499,
      "grad_norm": 0.39135846495628357,
      "learning_rate": 0.00015349669111071364,
      "loss": 2.4726,
      "step": 4600
    },
    {
      "epoch": 1.0695187165775402,
      "grad_norm": 0.39250707626342773,
      "learning_rate": 0.00015170810230727956,
      "loss": 2.4686,
      "step": 4700
    },
    {
      "epoch": 1.0922744339515302,
      "grad_norm": 0.38349786400794983,
      "learning_rate": 0.00014991951350384547,
      "loss": 2.4752,
      "step": 4800
    },
    {
      "epoch": 1.1150301513255205,
      "grad_norm": 0.3702239692211151,
      "learning_rate": 0.00014813092470041138,
      "loss": 2.4635,
      "step": 4900
    },
    {
      "epoch": 1.1377858686995108,
      "grad_norm": 0.3640730381011963,
      "learning_rate": 0.0001463423358969773,
      "loss": 2.4628,
      "step": 5000
    },
    {
      "epoch": 1.1377858686995108,
      "eval_loss": 2.5376460552215576,
      "eval_runtime": 14.0501,
      "eval_samples_per_second": 396.226,
      "eval_steps_per_second": 24.769,
      "step": 5000
    },
    {
      "epoch": 1.1605415860735009,
      "grad_norm": 0.37936627864837646,
      "learning_rate": 0.00014455374709354318,
      "loss": 2.4609,
      "step": 5100
    },
    {
      "epoch": 1.1832973034474912,
      "grad_norm": 0.3733771741390228,
      "learning_rate": 0.0001427651582901091,
      "loss": 2.4554,
      "step": 5200
    },
    {
      "epoch": 1.2060530208214815,
      "grad_norm": 0.34651845693588257,
      "learning_rate": 0.000140976569486675,
      "loss": 2.4562,
      "step": 5300
    },
    {
      "epoch": 1.2288087381954715,
      "grad_norm": 0.3522626757621765,
      "learning_rate": 0.00013918798068324092,
      "loss": 2.4535,
      "step": 5400
    },
    {
      "epoch": 1.2515644555694618,
      "grad_norm": 0.3635941743850708,
      "learning_rate": 0.00013739939187980683,
      "loss": 2.4478,
      "step": 5500
    },
    {
      "epoch": 1.2743201729434521,
      "grad_norm": 0.37049365043640137,
      "learning_rate": 0.00013561080307637275,
      "loss": 2.4424,
      "step": 5600
    },
    {
      "epoch": 1.2970758903174422,
      "grad_norm": 0.35896918177604675,
      "learning_rate": 0.00013382221427293866,
      "loss": 2.4426,
      "step": 5700
    },
    {
      "epoch": 1.3198316076914325,
      "grad_norm": 0.358498215675354,
      "learning_rate": 0.00013203362546950457,
      "loss": 2.4422,
      "step": 5800
    },
    {
      "epoch": 1.3425873250654226,
      "grad_norm": 0.36829674243927,
      "learning_rate": 0.00013024503666607049,
      "loss": 2.4465,
      "step": 5900
    },
    {
      "epoch": 1.3653430424394128,
      "grad_norm": 0.3659956753253937,
      "learning_rate": 0.00012845644786263637,
      "loss": 2.4399,
      "step": 6000
    },
    {
      "epoch": 1.3653430424394128,
      "eval_loss": 2.512653350830078,
      "eval_runtime": 14.0878,
      "eval_samples_per_second": 395.163,
      "eval_steps_per_second": 24.702,
      "step": 6000
    },
    {
      "epoch": 1.3880987598134031,
      "grad_norm": 0.3619515597820282,
      "learning_rate": 0.00012666785905920229,
      "loss": 2.4347,
      "step": 6100
    },
    {
      "epoch": 1.4108544771873932,
      "grad_norm": 0.34643441438674927,
      "learning_rate": 0.0001248792702557682,
      "loss": 2.4343,
      "step": 6200
    },
    {
      "epoch": 1.4336101945613835,
      "grad_norm": 0.3801872134208679,
      "learning_rate": 0.0001230906814523341,
      "loss": 2.4327,
      "step": 6300
    },
    {
      "epoch": 1.4563659119353738,
      "grad_norm": 0.3550300896167755,
      "learning_rate": 0.00012130209264890002,
      "loss": 2.428,
      "step": 6400
    },
    {
      "epoch": 1.4791216293093639,
      "grad_norm": 0.3638359606266022,
      "learning_rate": 0.00011951350384546594,
      "loss": 2.4242,
      "step": 6500
    },
    {
      "epoch": 1.5018773466833542,
      "grad_norm": 0.33735597133636475,
      "learning_rate": 0.00011772491504203185,
      "loss": 2.4256,
      "step": 6600
    },
    {
      "epoch": 1.5246330640573444,
      "grad_norm": 0.3482699692249298,
      "learning_rate": 0.00011593632623859776,
      "loss": 2.4235,
      "step": 6700
    },
    {
      "epoch": 1.5473887814313345,
      "grad_norm": 0.3659732937812805,
      "learning_rate": 0.00011414773743516368,
      "loss": 2.4212,
      "step": 6800
    },
    {
      "epoch": 1.5701444988053248,
      "grad_norm": 0.36769264936447144,
      "learning_rate": 0.00011235914863172956,
      "loss": 2.4188,
      "step": 6900
    },
    {
      "epoch": 1.592900216179315,
      "grad_norm": 0.3662330210208893,
      "learning_rate": 0.00011057055982829548,
      "loss": 2.4149,
      "step": 7000
    },
    {
      "epoch": 1.592900216179315,
      "eval_loss": 2.492414951324463,
      "eval_runtime": 14.1055,
      "eval_samples_per_second": 394.668,
      "eval_steps_per_second": 24.671,
      "step": 7000
    },
    {
      "epoch": 1.6156559335533052,
      "grad_norm": 0.34759950637817383,
      "learning_rate": 0.00010878197102486139,
      "loss": 2.4117,
      "step": 7100
    },
    {
      "epoch": 1.6384116509272955,
      "grad_norm": 0.3457738757133484,
      "learning_rate": 0.0001069933822214273,
      "loss": 2.4127,
      "step": 7200
    },
    {
      "epoch": 1.6611673683012858,
      "grad_norm": 0.3659059405326843,
      "learning_rate": 0.0001052047934179932,
      "loss": 2.4095,
      "step": 7300
    },
    {
      "epoch": 1.6839230856752758,
      "grad_norm": 0.35284698009490967,
      "learning_rate": 0.00010341620461455912,
      "loss": 2.405,
      "step": 7400
    },
    {
      "epoch": 1.7066788030492661,
      "grad_norm": 0.36525043845176697,
      "learning_rate": 0.00010162761581112503,
      "loss": 2.4062,
      "step": 7500
    },
    {
      "epoch": 1.7294345204232564,
      "grad_norm": 0.36927565932273865,
      "learning_rate": 9.983902700769093e-05,
      "loss": 2.4035,
      "step": 7600
    },
    {
      "epoch": 1.7521902377972465,
      "grad_norm": 0.34077924489974976,
      "learning_rate": 9.805043820425684e-05,
      "loss": 2.3998,
      "step": 7700
    },
    {
      "epoch": 1.7749459551712368,
      "grad_norm": 0.3537072241306305,
      "learning_rate": 9.626184940082275e-05,
      "loss": 2.397,
      "step": 7800
    },
    {
      "epoch": 1.797701672545227,
      "grad_norm": 0.3511955142021179,
      "learning_rate": 9.447326059738867e-05,
      "loss": 2.3968,
      "step": 7900
    },
    {
      "epoch": 1.8204573899192171,
      "grad_norm": 0.33354315161705017,
      "learning_rate": 9.268467179395457e-05,
      "loss": 2.3945,
      "step": 8000
    },
    {
      "epoch": 1.8204573899192171,
      "eval_loss": 2.4750378131866455,
      "eval_runtime": 14.0803,
      "eval_samples_per_second": 395.375,
      "eval_steps_per_second": 24.715,
      "step": 8000
    },
    {
      "epoch": 1.8432131072932074,
      "grad_norm": 0.3372114896774292,
      "learning_rate": 9.089608299052048e-05,
      "loss": 2.3948,
      "step": 8100
    },
    {
      "epoch": 1.8659688246671977,
      "grad_norm": 0.3448232114315033,
      "learning_rate": 8.91074941870864e-05,
      "loss": 2.3959,
      "step": 8200
    },
    {
      "epoch": 1.8887245420411878,
      "grad_norm": 0.34931379556655884,
      "learning_rate": 8.73189053836523e-05,
      "loss": 2.3914,
      "step": 8300
    },
    {
      "epoch": 1.911480259415178,
      "grad_norm": 0.3440432548522949,
      "learning_rate": 8.553031658021822e-05,
      "loss": 2.3904,
      "step": 8400
    },
    {
      "epoch": 1.9342359767891684,
      "grad_norm": 0.3511185944080353,
      "learning_rate": 8.374172777678412e-05,
      "loss": 2.3893,
      "step": 8500
    },
    {
      "epoch": 1.9569916941631584,
      "grad_norm": 0.35160988569259644,
      "learning_rate": 8.195313897335003e-05,
      "loss": 2.3811,
      "step": 8600
    },
    {
      "epoch": 1.9797474115371487,
      "grad_norm": 0.3531004786491394,
      "learning_rate": 8.016455016991595e-05,
      "loss": 2.3834,
      "step": 8700
    },
    {
      "epoch": 2.002503128911139,
      "grad_norm": 0.36236807703971863,
      "learning_rate": 7.837596136648186e-05,
      "loss": 2.3777,
      "step": 8800
    },
    {
      "epoch": 2.025258846285129,
      "grad_norm": 0.37610292434692383,
      "learning_rate": 7.658737256304776e-05,
      "loss": 2.3506,
      "step": 8900
    },
    {
      "epoch": 2.048014563659119,
      "grad_norm": 0.36899396777153015,
      "learning_rate": 7.479878375961367e-05,
      "loss": 2.3505,
      "step": 9000
    },
    {
      "epoch": 2.048014563659119,
      "eval_loss": 2.4607601165771484,
      "eval_runtime": 14.1046,
      "eval_samples_per_second": 394.694,
      "eval_steps_per_second": 24.673,
      "step": 9000
    },
    {
      "epoch": 2.0707702810331097,
      "grad_norm": 0.351304829120636,
      "learning_rate": 7.301019495617958e-05,
      "loss": 2.3482,
      "step": 9100
    },
    {
      "epoch": 2.0935259984070997,
      "grad_norm": 0.3566255569458008,
      "learning_rate": 7.122160615274548e-05,
      "loss": 2.3493,
      "step": 9200
    },
    {
      "epoch": 2.11628171578109,
      "grad_norm": 0.36535409092903137,
      "learning_rate": 6.94330173493114e-05,
      "loss": 2.3498,
      "step": 9300
    },
    {
      "epoch": 2.1390374331550803,
      "grad_norm": 0.3789095878601074,
      "learning_rate": 6.76444285458773e-05,
      "loss": 2.3475,
      "step": 9400
    },
    {
      "epoch": 2.1617931505290704,
      "grad_norm": 0.36262229084968567,
      "learning_rate": 6.585583974244321e-05,
      "loss": 2.3458,
      "step": 9500
    },
    {
      "epoch": 2.1845488679030605,
      "grad_norm": 0.36903247237205505,
      "learning_rate": 6.406725093900912e-05,
      "loss": 2.3449,
      "step": 9600
    },
    {
      "epoch": 2.207304585277051,
      "grad_norm": 0.3570692837238312,
      "learning_rate": 6.227866213557504e-05,
      "loss": 2.3476,
      "step": 9700
    },
    {
      "epoch": 2.230060302651041,
      "grad_norm": 0.39123669266700745,
      "learning_rate": 6.049007333214094e-05,
      "loss": 2.3426,
      "step": 9800
    },
    {
      "epoch": 2.252816020025031,
      "grad_norm": 0.3841557800769806,
      "learning_rate": 5.870148452870685e-05,
      "loss": 2.3393,
      "step": 9900
    },
    {
      "epoch": 2.2755717373990216,
      "grad_norm": 0.3667045533657074,
      "learning_rate": 5.691289572527276e-05,
      "loss": 2.3381,
      "step": 10000
    },
    {
      "epoch": 2.2755717373990216,
      "eval_loss": 2.449765682220459,
      "eval_runtime": 14.0062,
      "eval_samples_per_second": 397.467,
      "eval_steps_per_second": 24.846,
      "step": 10000
    },
    {
      "epoch": 2.2983274547730117,
      "grad_norm": 0.3680509924888611,
      "learning_rate": 5.5124306921838675e-05,
      "loss": 2.3428,
      "step": 10100
    },
    {
      "epoch": 2.3210831721470018,
      "grad_norm": 0.3695065975189209,
      "learning_rate": 5.3335718118404575e-05,
      "loss": 2.3394,
      "step": 10200
    },
    {
      "epoch": 2.3438388895209923,
      "grad_norm": 0.37832581996917725,
      "learning_rate": 5.154712931497049e-05,
      "loss": 2.3407,
      "step": 10300
    },
    {
      "epoch": 2.3665946068949824,
      "grad_norm": 0.3694941997528076,
      "learning_rate": 4.97585405115364e-05,
      "loss": 2.3395,
      "step": 10400
    },
    {
      "epoch": 2.3893503242689724,
      "grad_norm": 0.38006874918937683,
      "learning_rate": 4.7969951708102314e-05,
      "loss": 2.3322,
      "step": 10500
    },
    {
      "epoch": 2.412106041642963,
      "grad_norm": 0.36474665999412537,
      "learning_rate": 4.618136290466822e-05,
      "loss": 2.3356,
      "step": 10600
    },
    {
      "epoch": 2.434861759016953,
      "grad_norm": 0.37240326404571533,
      "learning_rate": 4.439277410123413e-05,
      "loss": 2.3324,
      "step": 10700
    },
    {
      "epoch": 2.457617476390943,
      "grad_norm": 0.3805142045021057,
      "learning_rate": 4.2604185297800033e-05,
      "loss": 2.3331,
      "step": 10800
    },
    {
      "epoch": 2.4803731937649336,
      "grad_norm": 0.36921370029449463,
      "learning_rate": 4.0815596494365947e-05,
      "loss": 2.3312,
      "step": 10900
    },
    {
      "epoch": 2.5031289111389237,
      "grad_norm": 0.37963032722473145,
      "learning_rate": 3.902700769093185e-05,
      "loss": 2.3306,
      "step": 11000
    },
    {
      "epoch": 2.5031289111389237,
      "eval_loss": 2.437329053878784,
      "eval_runtime": 14.0493,
      "eval_samples_per_second": 396.248,
      "eval_steps_per_second": 24.77,
      "step": 11000
    },
    {
      "epoch": 2.5258846285129137,
      "grad_norm": 0.3659180998802185,
      "learning_rate": 3.7238418887497766e-05,
      "loss": 2.3311,
      "step": 11100
    },
    {
      "epoch": 2.5486403458869042,
      "grad_norm": 0.38687631487846375,
      "learning_rate": 3.544983008406367e-05,
      "loss": 2.3286,
      "step": 11200
    },
    {
      "epoch": 2.5713960632608943,
      "grad_norm": 0.3845037519931793,
      "learning_rate": 3.3661241280629586e-05,
      "loss": 2.3286,
      "step": 11300
    },
    {
      "epoch": 2.5941517806348844,
      "grad_norm": 0.3811298608779907,
      "learning_rate": 3.187265247719549e-05,
      "loss": 2.3247,
      "step": 11400
    },
    {
      "epoch": 2.6169074980088745,
      "grad_norm": 0.37072837352752686,
      "learning_rate": 3.0084063673761405e-05,
      "loss": 2.3229,
      "step": 11500
    },
    {
      "epoch": 2.639663215382865,
      "grad_norm": 0.3826603889465332,
      "learning_rate": 2.8295474870327315e-05,
      "loss": 2.3241,
      "step": 11600
    },
    {
      "epoch": 2.662418932756855,
      "grad_norm": 0.3626563549041748,
      "learning_rate": 2.650688606689322e-05,
      "loss": 2.3176,
      "step": 11700
    },
    {
      "epoch": 2.685174650130845,
      "grad_norm": 0.3829975426197052,
      "learning_rate": 2.471829726345913e-05,
      "loss": 2.3211,
      "step": 11800
    },
    {
      "epoch": 2.7079303675048356,
      "grad_norm": 0.36216315627098083,
      "learning_rate": 2.292970846002504e-05,
      "loss": 2.3203,
      "step": 11900
    },
    {
      "epoch": 2.7306860848788257,
      "grad_norm": 0.3636576533317566,
      "learning_rate": 2.114111965659095e-05,
      "loss": 2.317,
      "step": 12000
    },
    {
      "epoch": 2.7306860848788257,
      "eval_loss": 2.429001569747925,
      "eval_runtime": 14.1024,
      "eval_samples_per_second": 394.755,
      "eval_steps_per_second": 24.677,
      "step": 12000
    },
    {
      "epoch": 2.7534418022528158,
      "grad_norm": 0.370540589094162,
      "learning_rate": 1.935253085315686e-05,
      "loss": 2.3144,
      "step": 12100
    },
    {
      "epoch": 2.7761975196268063,
      "grad_norm": 0.37620308995246887,
      "learning_rate": 1.756394204972277e-05,
      "loss": 2.3159,
      "step": 12200
    },
    {
      "epoch": 2.7989532370007963,
      "grad_norm": 0.3793651759624481,
      "learning_rate": 1.577535324628868e-05,
      "loss": 2.3154,
      "step": 12300
    },
    {
      "epoch": 2.8217089543747864,
      "grad_norm": 0.38198548555374146,
      "learning_rate": 1.398676444285459e-05,
      "loss": 2.3118,
      "step": 12400
    },
    {
      "epoch": 2.844464671748777,
      "grad_norm": 0.37038856744766235,
      "learning_rate": 1.2198175639420497e-05,
      "loss": 2.3153,
      "step": 12500
    },
    {
      "epoch": 2.867220389122767,
      "grad_norm": 0.3545527160167694,
      "learning_rate": 1.0409586835986407e-05,
      "loss": 2.3136,
      "step": 12600
    },
    {
      "epoch": 2.889976106496757,
      "grad_norm": 0.3707013428211212,
      "learning_rate": 8.620998032552315e-06,
      "loss": 2.3134,
      "step": 12700
    },
    {
      "epoch": 2.9127318238707476,
      "grad_norm": 0.37988972663879395,
      "learning_rate": 6.832409229118227e-06,
      "loss": 2.3111,
      "step": 12800
    },
    {
      "epoch": 2.9354875412447377,
      "grad_norm": 0.38202181458473206,
      "learning_rate": 5.0438204256841356e-06,
      "loss": 2.3132,
      "step": 12900
    },
    {
      "epoch": 2.9582432586187277,
      "grad_norm": 0.3760532736778259,
      "learning_rate": 3.255231622250045e-06,
      "loss": 2.3077,
      "step": 13000
    },
    {
      "epoch": 2.9582432586187277,
      "eval_loss": 2.422773838043213,
      "eval_runtime": 14.0787,
      "eval_samples_per_second": 395.419,
      "eval_steps_per_second": 24.718,
      "step": 13000
    },
    {
      "epoch": 2.9809989759927182,
      "grad_norm": 0.3761194944381714,
      "learning_rate": 1.4666428188159542e-06,
      "loss": 2.3097,
      "step": 13100
    }
  ],
  "logging_steps": 100,
  "max_steps": 13182,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.269996624549929e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
