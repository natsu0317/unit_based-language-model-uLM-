{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 13185,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.022755717373990215,
      "grad_norm": 0.5768023133277893,
      "learning_rate": 2.97e-05,
      "loss": 6.1951,
      "step": 100
    },
    {
      "epoch": 0.04551143474798043,
      "grad_norm": 2.92033314704895,
      "learning_rate": 5.97e-05,
      "loss": 3.8586,
      "step": 200
    },
    {
      "epoch": 0.06826715212197064,
      "grad_norm": 2.661097764968872,
      "learning_rate": 8.969999999999998e-05,
      "loss": 3.0072,
      "step": 300
    },
    {
      "epoch": 0.09102286949596086,
      "grad_norm": 2.218278646469116,
      "learning_rate": 0.0001197,
      "loss": 2.9067,
      "step": 400
    },
    {
      "epoch": 0.11377858686995107,
      "grad_norm": 2.0276644229888916,
      "learning_rate": 0.00014969999999999998,
      "loss": 2.8577,
      "step": 500
    },
    {
      "epoch": 0.13653430424394128,
      "grad_norm": 1.8812006711959839,
      "learning_rate": 0.00017969999999999998,
      "loss": 2.824,
      "step": 600
    },
    {
      "epoch": 0.15929002161793152,
      "grad_norm": 1.4751560688018799,
      "learning_rate": 0.00020969999999999997,
      "loss": 2.7948,
      "step": 700
    },
    {
      "epoch": 0.18204573899192172,
      "grad_norm": 1.1834625005722046,
      "learning_rate": 0.0002397,
      "loss": 2.7671,
      "step": 800
    },
    {
      "epoch": 0.20480145636591193,
      "grad_norm": 0.9881269931793213,
      "learning_rate": 0.0002697,
      "loss": 2.7493,
      "step": 900
    },
    {
      "epoch": 0.22755717373990214,
      "grad_norm": 0.8419995903968811,
      "learning_rate": 0.00029969999999999997,
      "loss": 2.7251,
      "step": 1000
    },
    {
      "epoch": 0.2503128911138924,
      "grad_norm": 0.7541968822479248,
      "learning_rate": 0.00029756257693885923,
      "loss": 2.6996,
      "step": 1100
    },
    {
      "epoch": 0.27306860848788256,
      "grad_norm": 0.7289255261421204,
      "learning_rate": 0.00029510053344275743,
      "loss": 2.6775,
      "step": 1200
    },
    {
      "epoch": 0.2958243258618728,
      "grad_norm": 0.7130678296089172,
      "learning_rate": 0.0002926384899466557,
      "loss": 2.6546,
      "step": 1300
    },
    {
      "epoch": 0.31858004323586303,
      "grad_norm": 0.6488452553749084,
      "learning_rate": 0.00029017644645055394,
      "loss": 2.6423,
      "step": 1400
    },
    {
      "epoch": 0.3413357606098532,
      "grad_norm": 0.6266946792602539,
      "learning_rate": 0.00028771440295445214,
      "loss": 2.6266,
      "step": 1500
    },
    {
      "epoch": 0.36409147798384345,
      "grad_norm": 0.5036617517471313,
      "learning_rate": 0.0002852523594583504,
      "loss": 2.6135,
      "step": 1600
    },
    {
      "epoch": 0.38684719535783363,
      "grad_norm": 0.558563232421875,
      "learning_rate": 0.00028279031596224866,
      "loss": 2.5978,
      "step": 1700
    },
    {
      "epoch": 0.40960291273182386,
      "grad_norm": 0.505571722984314,
      "learning_rate": 0.00028032827246614686,
      "loss": 2.5898,
      "step": 1800
    },
    {
      "epoch": 0.4323586301058141,
      "grad_norm": 0.49641698598861694,
      "learning_rate": 0.0002778662289700451,
      "loss": 2.5779,
      "step": 1900
    },
    {
      "epoch": 0.4551143474798043,
      "grad_norm": 0.5193657875061035,
      "learning_rate": 0.00027540418547394337,
      "loss": 2.5703,
      "step": 2000
    },
    {
      "epoch": 0.4778700648537945,
      "grad_norm": 0.4905215799808502,
      "learning_rate": 0.00027294214197784157,
      "loss": 2.5631,
      "step": 2100
    },
    {
      "epoch": 0.5006257822277848,
      "grad_norm": 0.5681113004684448,
      "learning_rate": 0.0002704800984817398,
      "loss": 2.5583,
      "step": 2200
    },
    {
      "epoch": 0.5233814996017749,
      "grad_norm": 0.5421723127365112,
      "learning_rate": 0.0002680180549856381,
      "loss": 2.5503,
      "step": 2300
    },
    {
      "epoch": 0.5461372169757651,
      "grad_norm": 0.4804306626319885,
      "learning_rate": 0.0002655560114895363,
      "loss": 2.543,
      "step": 2400
    },
    {
      "epoch": 0.5688929343497554,
      "grad_norm": 0.5025319457054138,
      "learning_rate": 0.00026309396799343454,
      "loss": 2.5346,
      "step": 2500
    },
    {
      "epoch": 0.5916486517237456,
      "grad_norm": 0.46854543685913086,
      "learning_rate": 0.0002606319244973328,
      "loss": 2.5272,
      "step": 2600
    },
    {
      "epoch": 0.6144043690977358,
      "grad_norm": 0.4677320122718811,
      "learning_rate": 0.000258169881001231,
      "loss": 2.524,
      "step": 2700
    },
    {
      "epoch": 0.6371600864717261,
      "grad_norm": 0.45794984698295593,
      "learning_rate": 0.0002557078375051292,
      "loss": 2.5148,
      "step": 2800
    },
    {
      "epoch": 0.6599158038457162,
      "grad_norm": 0.4463071823120117,
      "learning_rate": 0.00025324579400902745,
      "loss": 2.5098,
      "step": 2900
    },
    {
      "epoch": 0.6826715212197064,
      "grad_norm": 0.47850465774536133,
      "learning_rate": 0.0002507837505129257,
      "loss": 2.5087,
      "step": 3000
    },
    {
      "epoch": 0.7054272385936967,
      "grad_norm": 0.4446601867675781,
      "learning_rate": 0.0002483217070168239,
      "loss": 2.5052,
      "step": 3100
    },
    {
      "epoch": 0.7281829559676869,
      "grad_norm": 0.47681817412376404,
      "learning_rate": 0.00024585966352072216,
      "loss": 2.5012,
      "step": 3200
    },
    {
      "epoch": 0.7509386733416771,
      "grad_norm": 0.48491615056991577,
      "learning_rate": 0.00024339762002462042,
      "loss": 2.4941,
      "step": 3300
    },
    {
      "epoch": 0.7736943907156673,
      "grad_norm": 0.4645215570926666,
      "learning_rate": 0.00024093557652851865,
      "loss": 2.486,
      "step": 3400
    },
    {
      "epoch": 0.7964501080896575,
      "grad_norm": 0.47581228613853455,
      "learning_rate": 0.00023847353303241688,
      "loss": 2.4836,
      "step": 3500
    },
    {
      "epoch": 0.8192058254636477,
      "grad_norm": 0.43962591886520386,
      "learning_rate": 0.00023601148953631513,
      "loss": 2.4818,
      "step": 3600
    },
    {
      "epoch": 0.8419615428376379,
      "grad_norm": 0.40663227438926697,
      "learning_rate": 0.00023354944604021336,
      "loss": 2.4801,
      "step": 3700
    },
    {
      "epoch": 0.8647172602116282,
      "grad_norm": 0.5078651309013367,
      "learning_rate": 0.0002310874025441116,
      "loss": 2.4722,
      "step": 3800
    },
    {
      "epoch": 0.8874729775856184,
      "grad_norm": 0.4372050166130066,
      "learning_rate": 0.00022862535904800984,
      "loss": 2.4718,
      "step": 3900
    },
    {
      "epoch": 0.9102286949596086,
      "grad_norm": 0.41942936182022095,
      "learning_rate": 0.00022616331555190807,
      "loss": 2.4692,
      "step": 4000
    },
    {
      "epoch": 0.9329844123335989,
      "grad_norm": 0.4065101146697998,
      "learning_rate": 0.0002237012720558063,
      "loss": 2.4646,
      "step": 4100
    },
    {
      "epoch": 0.955740129707589,
      "grad_norm": 0.4144536554813385,
      "learning_rate": 0.00022123922855970456,
      "loss": 2.4604,
      "step": 4200
    },
    {
      "epoch": 0.9784958470815792,
      "grad_norm": 0.4665079712867737,
      "learning_rate": 0.00021877718506360276,
      "loss": 2.4584,
      "step": 4300
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.537564277648926,
      "eval_model_preparation_time": 0.0191,
      "eval_runtime": 129.3453,
      "eval_samples_per_second": 43.04,
      "eval_steps_per_second": 2.69,
      "step": 4395
    },
    {
      "epoch": 1.0011377858686996,
      "grad_norm": 0.4145055115222931,
      "learning_rate": 0.00021631514156750099,
      "loss": 2.4551,
      "step": 4400
    },
    {
      "epoch": 1.0238935032426897,
      "grad_norm": 0.43006664514541626,
      "learning_rate": 0.00021385309807139924,
      "loss": 2.436,
      "step": 4500
    },
    {
      "epoch": 1.04664922061668,
      "grad_norm": 0.4174211919307709,
      "learning_rate": 0.00021139105457529747,
      "loss": 2.4358,
      "step": 4600
    },
    {
      "epoch": 1.06940493799067,
      "grad_norm": 0.4149801731109619,
      "learning_rate": 0.0002089290110791957,
      "loss": 2.4317,
      "step": 4700
    },
    {
      "epoch": 1.0921606553646603,
      "grad_norm": 0.4211325943470001,
      "learning_rate": 0.00020646696758309395,
      "loss": 2.4387,
      "step": 4800
    },
    {
      "epoch": 1.1149163727386506,
      "grad_norm": 0.44237813353538513,
      "learning_rate": 0.00020400492408699218,
      "loss": 2.4281,
      "step": 4900
    },
    {
      "epoch": 1.1376720901126407,
      "grad_norm": 0.43640005588531494,
      "learning_rate": 0.0002015428805908904,
      "loss": 2.428,
      "step": 5000
    },
    {
      "epoch": 1.160427807486631,
      "grad_norm": 0.4134085774421692,
      "learning_rate": 0.00019908083709478867,
      "loss": 2.4265,
      "step": 5100
    },
    {
      "epoch": 1.1831835248606213,
      "grad_norm": 0.42252108454704285,
      "learning_rate": 0.0001966187935986869,
      "loss": 2.4222,
      "step": 5200
    },
    {
      "epoch": 1.2059392422346114,
      "grad_norm": 0.4172624349594116,
      "learning_rate": 0.00019415675010258512,
      "loss": 2.425,
      "step": 5300
    },
    {
      "epoch": 1.2286949596086016,
      "grad_norm": 0.43239471316337585,
      "learning_rate": 0.00019169470660648338,
      "loss": 2.4215,
      "step": 5400
    },
    {
      "epoch": 1.251450676982592,
      "grad_norm": 0.4091077446937561,
      "learning_rate": 0.0001892326631103816,
      "loss": 2.4178,
      "step": 5500
    },
    {
      "epoch": 1.274206394356582,
      "grad_norm": 0.40519747138023376,
      "learning_rate": 0.00018677061961427984,
      "loss": 2.4113,
      "step": 5600
    },
    {
      "epoch": 1.2969621117305723,
      "grad_norm": 0.41842561960220337,
      "learning_rate": 0.0001843085761181781,
      "loss": 2.4132,
      "step": 5700
    },
    {
      "epoch": 1.3197178291045626,
      "grad_norm": 0.4155910611152649,
      "learning_rate": 0.0001818465326220763,
      "loss": 2.4134,
      "step": 5800
    },
    {
      "epoch": 1.3424735464785527,
      "grad_norm": 0.3992498517036438,
      "learning_rate": 0.00017938448912597452,
      "loss": 2.419,
      "step": 5900
    },
    {
      "epoch": 1.365229263852543,
      "grad_norm": 0.4156659245491028,
      "learning_rate": 0.00017692244562987278,
      "loss": 2.4116,
      "step": 6000
    },
    {
      "epoch": 1.3879849812265332,
      "grad_norm": 0.4307781755924225,
      "learning_rate": 0.000174460402133771,
      "loss": 2.4083,
      "step": 6100
    },
    {
      "epoch": 1.4107406986005233,
      "grad_norm": 0.4077710807323456,
      "learning_rate": 0.00017199835863766923,
      "loss": 2.4093,
      "step": 6200
    },
    {
      "epoch": 1.4334964159745136,
      "grad_norm": 0.4432634115219116,
      "learning_rate": 0.0001695363151415675,
      "loss": 2.4065,
      "step": 6300
    },
    {
      "epoch": 1.456252133348504,
      "grad_norm": 0.44331780076026917,
      "learning_rate": 0.00016707427164546572,
      "loss": 2.4037,
      "step": 6400
    },
    {
      "epoch": 1.479007850722494,
      "grad_norm": 0.3992402255535126,
      "learning_rate": 0.00016461222814936395,
      "loss": 2.4001,
      "step": 6500
    },
    {
      "epoch": 1.5017635680964843,
      "grad_norm": 0.41136792302131653,
      "learning_rate": 0.0001621501846532622,
      "loss": 2.4011,
      "step": 6600
    },
    {
      "epoch": 1.5245192854704745,
      "grad_norm": 0.3878819942474365,
      "learning_rate": 0.00015968814115716043,
      "loss": 2.4016,
      "step": 6700
    },
    {
      "epoch": 1.5472750028444646,
      "grad_norm": 0.4516337215900421,
      "learning_rate": 0.00015722609766105866,
      "loss": 2.3992,
      "step": 6800
    },
    {
      "epoch": 1.570030720218455,
      "grad_norm": 0.40030917525291443,
      "learning_rate": 0.00015476405416495691,
      "loss": 2.3964,
      "step": 6900
    },
    {
      "epoch": 1.5927864375924452,
      "grad_norm": 0.4233688712120056,
      "learning_rate": 0.00015230201066885514,
      "loss": 2.3933,
      "step": 7000
    },
    {
      "epoch": 1.6155421549664353,
      "grad_norm": 0.39995503425598145,
      "learning_rate": 0.00014983996717275337,
      "loss": 2.3907,
      "step": 7100
    },
    {
      "epoch": 1.6382978723404256,
      "grad_norm": 0.3842499852180481,
      "learning_rate": 0.0001473779236766516,
      "loss": 2.3924,
      "step": 7200
    },
    {
      "epoch": 1.6610535897144159,
      "grad_norm": 0.42085886001586914,
      "learning_rate": 0.00014491588018054985,
      "loss": 2.3904,
      "step": 7300
    },
    {
      "epoch": 1.683809307088406,
      "grad_norm": 0.4045523703098297,
      "learning_rate": 0.00014245383668444808,
      "loss": 2.3852,
      "step": 7400
    },
    {
      "epoch": 1.7065650244623962,
      "grad_norm": 0.41681909561157227,
      "learning_rate": 0.0001399917931883463,
      "loss": 2.3873,
      "step": 7500
    },
    {
      "epoch": 1.7293207418363865,
      "grad_norm": 0.43117594718933105,
      "learning_rate": 0.00013752974969224457,
      "loss": 2.3859,
      "step": 7600
    },
    {
      "epoch": 1.7520764592103766,
      "grad_norm": 0.42530009150505066,
      "learning_rate": 0.0001350677061961428,
      "loss": 2.3809,
      "step": 7700
    },
    {
      "epoch": 1.7748321765843669,
      "grad_norm": 0.4006738066673279,
      "learning_rate": 0.00013260566270004102,
      "loss": 2.3801,
      "step": 7800
    },
    {
      "epoch": 1.7975878939583572,
      "grad_norm": 0.41280174255371094,
      "learning_rate": 0.00013014361920393925,
      "loss": 2.3801,
      "step": 7900
    },
    {
      "epoch": 1.8203436113323472,
      "grad_norm": 0.39640623331069946,
      "learning_rate": 0.00012768157570783748,
      "loss": 2.3779,
      "step": 8000
    },
    {
      "epoch": 1.8430993287063373,
      "grad_norm": 0.4286862313747406,
      "learning_rate": 0.00012521953221173574,
      "loss": 2.3794,
      "step": 8100
    },
    {
      "epoch": 1.8658550460803278,
      "grad_norm": 0.39220550656318665,
      "learning_rate": 0.00012275748871563396,
      "loss": 2.3796,
      "step": 8200
    },
    {
      "epoch": 1.8886107634543179,
      "grad_norm": 0.3931122422218323,
      "learning_rate": 0.00012029544521953221,
      "loss": 2.3756,
      "step": 8300
    },
    {
      "epoch": 1.911366480828308,
      "grad_norm": 0.4055458605289459,
      "learning_rate": 0.00011783340172343045,
      "loss": 2.376,
      "step": 8400
    },
    {
      "epoch": 1.9341221982022985,
      "grad_norm": 0.37916940450668335,
      "learning_rate": 0.00011537135822732868,
      "loss": 2.3748,
      "step": 8500
    },
    {
      "epoch": 1.9568779155762885,
      "grad_norm": 0.384602427482605,
      "learning_rate": 0.0001129093147312269,
      "loss": 2.3678,
      "step": 8600
    },
    {
      "epoch": 1.9796336329502786,
      "grad_norm": 0.40761786699295044,
      "learning_rate": 0.00011044727123512513,
      "loss": 2.3706,
      "step": 8700
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.4674313068389893,
      "eval_model_preparation_time": 0.0191,
      "eval_runtime": 128.7354,
      "eval_samples_per_second": 43.244,
      "eval_steps_per_second": 2.703,
      "step": 8790
    },
    {
      "epoch": 2.0022755717373992,
      "grad_norm": 0.42001503705978394,
      "learning_rate": 0.00010798522773902338,
      "loss": 2.3659,
      "step": 8800
    },
    {
      "epoch": 2.0250312891113893,
      "grad_norm": 0.4171638488769531,
      "learning_rate": 0.00010552318424292162,
      "loss": 2.3424,
      "step": 8900
    },
    {
      "epoch": 2.0477870064853794,
      "grad_norm": 0.4139096438884735,
      "learning_rate": 0.00010306114074681986,
      "loss": 2.3411,
      "step": 9000
    },
    {
      "epoch": 2.0705427238593694,
      "grad_norm": 0.41402915120124817,
      "learning_rate": 0.00010059909725071809,
      "loss": 2.3416,
      "step": 9100
    },
    {
      "epoch": 2.09329844123336,
      "grad_norm": 0.44335779547691345,
      "learning_rate": 9.813705375461633e-05,
      "loss": 2.3421,
      "step": 9200
    },
    {
      "epoch": 2.11605415860735,
      "grad_norm": 0.40874648094177246,
      "learning_rate": 9.567501025851455e-05,
      "loss": 2.3443,
      "step": 9300
    },
    {
      "epoch": 2.13880987598134,
      "grad_norm": 0.4175821542739868,
      "learning_rate": 9.321296676241279e-05,
      "loss": 2.342,
      "step": 9400
    },
    {
      "epoch": 2.1615655933553306,
      "grad_norm": 0.4033798575401306,
      "learning_rate": 9.075092326631103e-05,
      "loss": 2.3399,
      "step": 9500
    },
    {
      "epoch": 2.1843213107293207,
      "grad_norm": 0.41759902238845825,
      "learning_rate": 8.828887977020926e-05,
      "loss": 2.3379,
      "step": 9600
    },
    {
      "epoch": 2.2070770281033107,
      "grad_norm": 0.4355562627315521,
      "learning_rate": 8.58268362741075e-05,
      "loss": 2.3412,
      "step": 9700
    },
    {
      "epoch": 2.2298327454773013,
      "grad_norm": 0.4372417628765106,
      "learning_rate": 8.336479277800574e-05,
      "loss": 2.3368,
      "step": 9800
    },
    {
      "epoch": 2.2525884628512913,
      "grad_norm": 0.42696401476860046,
      "learning_rate": 8.090274928190398e-05,
      "loss": 2.3348,
      "step": 9900
    },
    {
      "epoch": 2.2753441802252814,
      "grad_norm": 0.42112478613853455,
      "learning_rate": 7.844070578580221e-05,
      "loss": 2.334,
      "step": 10000
    },
    {
      "epoch": 2.298099897599272,
      "grad_norm": 0.4108775556087494,
      "learning_rate": 7.597866228970044e-05,
      "loss": 2.3375,
      "step": 10100
    },
    {
      "epoch": 2.320855614973262,
      "grad_norm": 0.4325478672981262,
      "learning_rate": 7.351661879359868e-05,
      "loss": 2.3368,
      "step": 10200
    },
    {
      "epoch": 2.343611332347252,
      "grad_norm": 0.4332006275653839,
      "learning_rate": 7.105457529749691e-05,
      "loss": 2.3366,
      "step": 10300
    },
    {
      "epoch": 2.3663670497212426,
      "grad_norm": 0.4273795187473297,
      "learning_rate": 6.859253180139515e-05,
      "loss": 2.3357,
      "step": 10400
    },
    {
      "epoch": 2.3891227670952326,
      "grad_norm": 0.4122796952724457,
      "learning_rate": 6.61304883052934e-05,
      "loss": 2.33,
      "step": 10500
    },
    {
      "epoch": 2.4118784844692227,
      "grad_norm": 0.42065203189849854,
      "learning_rate": 6.366844480919162e-05,
      "loss": 2.333,
      "step": 10600
    },
    {
      "epoch": 2.434634201843213,
      "grad_norm": 0.4219876229763031,
      "learning_rate": 6.120640131308985e-05,
      "loss": 2.3296,
      "step": 10700
    },
    {
      "epoch": 2.4573899192172033,
      "grad_norm": 0.44615617394447327,
      "learning_rate": 5.8744357816988094e-05,
      "loss": 2.331,
      "step": 10800
    },
    {
      "epoch": 2.4801456365911934,
      "grad_norm": 0.428880512714386,
      "learning_rate": 5.628231432088633e-05,
      "loss": 2.3296,
      "step": 10900
    },
    {
      "epoch": 2.502901353965184,
      "grad_norm": 0.4479183256626129,
      "learning_rate": 5.382027082478457e-05,
      "loss": 2.3296,
      "step": 11000
    },
    {
      "epoch": 2.525657071339174,
      "grad_norm": 0.4272848963737488,
      "learning_rate": 5.13582273286828e-05,
      "loss": 2.3292,
      "step": 11100
    },
    {
      "epoch": 2.548412788713164,
      "grad_norm": 0.4337998032569885,
      "learning_rate": 4.8896183832581035e-05,
      "loss": 2.3266,
      "step": 11200
    },
    {
      "epoch": 2.5711685060871545,
      "grad_norm": 0.4421810805797577,
      "learning_rate": 4.643414033647928e-05,
      "loss": 2.3282,
      "step": 11300
    },
    {
      "epoch": 2.5939242234611446,
      "grad_norm": 0.4267978370189667,
      "learning_rate": 4.397209684037751e-05,
      "loss": 2.3245,
      "step": 11400
    },
    {
      "epoch": 2.6166799408351347,
      "grad_norm": 0.4360930919647217,
      "learning_rate": 4.151005334427574e-05,
      "loss": 2.3232,
      "step": 11500
    },
    {
      "epoch": 2.639435658209125,
      "grad_norm": 0.4318448305130005,
      "learning_rate": 3.904800984817398e-05,
      "loss": 2.3246,
      "step": 11600
    },
    {
      "epoch": 2.6621913755831152,
      "grad_norm": 0.4220057427883148,
      "learning_rate": 3.658596635207222e-05,
      "loss": 2.3179,
      "step": 11700
    },
    {
      "epoch": 2.6849470929571053,
      "grad_norm": 0.44434529542922974,
      "learning_rate": 3.412392285597045e-05,
      "loss": 2.3225,
      "step": 11800
    },
    {
      "epoch": 2.707702810331096,
      "grad_norm": 0.430000901222229,
      "learning_rate": 3.166187935986869e-05,
      "loss": 2.321,
      "step": 11900
    },
    {
      "epoch": 2.730458527705086,
      "grad_norm": 0.43378734588623047,
      "learning_rate": 2.9199835863766924e-05,
      "loss": 2.3178,
      "step": 12000
    },
    {
      "epoch": 2.753214245079076,
      "grad_norm": 0.44409799575805664,
      "learning_rate": 2.6737792367665162e-05,
      "loss": 2.3164,
      "step": 12100
    },
    {
      "epoch": 2.7759699624530665,
      "grad_norm": 0.41671156883239746,
      "learning_rate": 2.4275748871563394e-05,
      "loss": 2.3173,
      "step": 12200
    },
    {
      "epoch": 2.7987256798270566,
      "grad_norm": 0.4388194978237152,
      "learning_rate": 2.181370537546163e-05,
      "loss": 2.3177,
      "step": 12300
    },
    {
      "epoch": 2.8214813972010466,
      "grad_norm": 0.4123302698135376,
      "learning_rate": 1.9351661879359868e-05,
      "loss": 2.3141,
      "step": 12400
    },
    {
      "epoch": 2.844237114575037,
      "grad_norm": 0.4351564049720764,
      "learning_rate": 1.6889618383258103e-05,
      "loss": 2.3176,
      "step": 12500
    },
    {
      "epoch": 2.866992831949027,
      "grad_norm": 0.42193403840065,
      "learning_rate": 1.4427574887156338e-05,
      "loss": 2.3172,
      "step": 12600
    },
    {
      "epoch": 2.8897485493230173,
      "grad_norm": 0.42103123664855957,
      "learning_rate": 1.1965531391054575e-05,
      "loss": 2.3163,
      "step": 12700
    },
    {
      "epoch": 2.912504266697008,
      "grad_norm": 0.42916926741600037,
      "learning_rate": 9.50348789495281e-06,
      "loss": 2.3134,
      "step": 12800
    },
    {
      "epoch": 2.935259984070998,
      "grad_norm": 0.44389787316322327,
      "learning_rate": 7.0414443988510466e-06,
      "loss": 2.3165,
      "step": 12900
    },
    {
      "epoch": 2.958015701444988,
      "grad_norm": 0.41908150911331177,
      "learning_rate": 4.579400902749282e-06,
      "loss": 2.3108,
      "step": 13000
    },
    {
      "epoch": 2.9807714188189784,
      "grad_norm": 0.42179298400878906,
      "learning_rate": 2.1173574066475174e-06,
      "loss": 2.3135,
      "step": 13100
    }
  ],
  "logging_steps": 100,
  "max_steps": 13185,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 5000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 6.068091629058613e+18,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
